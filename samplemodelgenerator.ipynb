{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.0-cp38-cp38-macosx_10_11_x86_64.whl (175.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 175.5 MB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.1 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-macosx_10_9_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.19.2)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py~=2.10.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 5.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 3.7 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.14.0-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 8.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (50.3.1.post20201107)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 4.3 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 9.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=689753ccf1dedd8cf08883b0e35b6da4b0c3b0fe92ed01db294f9de69a8f502b\n",
      "  Stored in directory: /Users/divyanshu30/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-macosx_10_9_x86_64.whl size=32721 sha256=80e7904a3f23760c78decb14f9da94f989946a6b94d7cbec69c426f374d4b098\n",
      "  Stored in directory: /Users/divyanshu30/Library/Caches/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: gast, opt-einsum, tensorboard-plugin-wit, protobuf, grpcio, markdown, absl-py, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, astunparse, tensorflow-estimator, keras-preprocessing, flatbuffers, termcolor, wrapt, google-pasta, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.3.3 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7 tensorboard-2.4.1 tensorboard-plugin-wit-1.7.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras\n",
    "#!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Dense, Dropout,Flatten,Activation\n",
    "from keras.losses import categorical_crossentropy ##as there is 10 catagories to choose from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "height = 92\n",
    "width = 200\n",
    "sample = 6\n",
    "model.add(Conv2D(16,input_shape=(height,width,3),kernel_size=(3,3)))  ##standard input size h=55,w=45,channels=1\n",
    "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4), padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('sigmoid')) ##sigmoid 'cuz it worked\n",
    "model.add(Dropout(rate=0.4)) ##standard\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('sigmoid')) ##sigmoid 'cuz it worked\n",
    "model.add(Dropout(rate=0.4)) ##standard\n",
    "\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('sigmoid')) ##sigmoid 'cuz it worked\n",
    "model.add(Dropout(rate=0.4)) ##standard\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(6)) ##last layer i.e. output layer: 10 catagory (0,1,2,3,4,5,6,7,8,9)\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy, optimizer='sgd', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 198, 16)       448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 49, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 17248)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              17249000  \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                3216      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 102       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 17,452,966\n",
      "Trainable params: 17,452,966\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1075 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('samples_no', ##input dir\n",
    "                                                 target_size = (height,width), ##standard we selected\n",
    "                                                 batch_size = 16, ##trade off between batch_size and step_per_epoch (given below)\n",
    "                                                 class_mode = 'categorical', ##10 catagories duh!\n",
    "                                                 shuffle=True,\n",
    "                                                 color_mode = 'rgb') ##all images are grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "68/68 [==============================] - 98s 1s/step - loss: 1.9365 - accuracy: 0.1872\n",
      "Epoch 2/24\n",
      "68/68 [==============================] - 110s 2s/step - loss: 1.8301 - accuracy: 0.2000\n",
      "Epoch 3/24\n",
      "68/68 [==============================] - 106s 2s/step - loss: 1.7719 - accuracy: 0.2103\n",
      "Epoch 4/24\n",
      "68/68 [==============================] - 108s 2s/step - loss: 1.6939 - accuracy: 0.3111\n",
      "Epoch 5/24\n",
      "68/68 [==============================] - 106s 2s/step - loss: 1.5738 - accuracy: 0.4128\n",
      "Epoch 6/24\n",
      "68/68 [==============================] - 113s 2s/step - loss: 1.5258 - accuracy: 0.4344\n",
      "Epoch 7/24\n",
      "68/68 [==============================] - 110s 2s/step - loss: 1.4276 - accuracy: 0.4926\n",
      "Epoch 8/24\n",
      "68/68 [==============================] - 109s 2s/step - loss: 1.3121 - accuracy: 0.5991\n",
      "Epoch 9/24\n",
      "68/68 [==============================] - 110s 2s/step - loss: 1.2267 - accuracy: 0.6215\n",
      "Epoch 10/24\n",
      "68/68 [==============================] - 100s 1s/step - loss: 1.1399 - accuracy: 0.6927\n",
      "Epoch 11/24\n",
      "68/68 [==============================] - 106s 2s/step - loss: 1.0678 - accuracy: 0.7054\n",
      "Epoch 12/24\n",
      "68/68 [==============================] - 111s 2s/step - loss: 1.0022 - accuracy: 0.7440\n",
      "Epoch 13/24\n",
      "68/68 [==============================] - 104s 2s/step - loss: 1.0030 - accuracy: 0.7202\n",
      "Epoch 14/24\n",
      "68/68 [==============================] - 100s 1s/step - loss: 0.9513 - accuracy: 0.7450\n",
      "Epoch 15/24\n",
      "68/68 [==============================] - 174s 3s/step - loss: 0.9075 - accuracy: 0.7602\n",
      "Epoch 16/24\n",
      "68/68 [==============================] - 107s 2s/step - loss: 0.7977 - accuracy: 0.8287\n",
      "Epoch 17/24\n",
      "68/68 [==============================] - 102s 2s/step - loss: 0.7749 - accuracy: 0.8084\n",
      "Epoch 18/24\n",
      "68/68 [==============================] - 103s 2s/step - loss: 0.7375 - accuracy: 0.8165\n",
      "Epoch 19/24\n",
      "68/68 [==============================] - 1099s 16s/step - loss: 0.7283 - accuracy: 0.8402\n",
      "Epoch 20/24\n",
      "68/68 [==============================] - 5385s 80s/step - loss: 0.6880 - accuracy: 0.8384\n",
      "Epoch 21/24\n",
      "68/68 [==============================] - 4322s 64s/step - loss: 0.6769 - accuracy: 0.8428\n",
      "Epoch 22/24\n",
      "68/68 [==============================] - 99s 1s/step - loss: 0.6391 - accuracy: 0.8752\n",
      "Epoch 23/24\n",
      "68/68 [==============================] - 109s 2s/step - loss: 0.6199 - accuracy: 0.8529\n",
      "Epoch 24/24\n",
      "68/68 [==============================] - 106s 2s/step - loss: 0.5896 - accuracy: 0.8628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf13c0ee50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_set,epochs =24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/tensorflowjs/converters/keras_h5_conversion.py:123: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  return h5py.File(h5file)\n"
     ]
    }
   ],
   "source": [
    "tfjs.converters.save_keras_model(model, 'cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
